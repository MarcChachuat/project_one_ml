{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functions import *\n",
    "from helpers import *\n",
    "from proj1_helpers import *\n",
    "from costs import *\n",
    "from data_preprocessing import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading of the data : done\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "# TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "print(\"loading of the data : done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functions import logistic_regression_GD\n",
    "\n",
    "def prediction(tx, w):\n",
    "    y = tx @ w\n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 0\n",
    "    return y\n",
    "\n",
    "def accuracy(y, y_pred):\n",
    "    return np.mean(y == y_pred)\n",
    "\n",
    "log_features = [1, 3, 4, 5, 8, 9, 13, 16, 19, 23, 26, 29]\n",
    "normal_features = [0, 2, 6, 7, 10, 14, 17, 21, 24, 27]\n",
    "uniform_feature = [15, 18, 20, 25, 28]\n",
    "# two side are large\n",
    "bernoulli_feature = [11, 12]\n",
    "categorical_features = [22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "# TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "print(\"loading of the data : done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_total_training_samples = tX.shape[0]\n",
    "n_total_features         = tX.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_with_missing_values = []\n",
    "for i in range(n_total_features):\n",
    "    if -999 in tX[:, i]:\n",
    "        columns_with_missing_values.append(i)\n",
    "\n",
    "columns_with_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_features = [1, 3, 4, 5, 8, 9, 13, 16, 19, 23, 26, 29]\n",
    "normal_features = [0, 2, 6, 7, 10, 14, 17, 21, 24, 27]\n",
    "uniform_feature = [15, 18, 20, 25, 28]\n",
    "# two side are large (perhaps beta distribution)\n",
    "bernoulli_feature = [11, 12]\n",
    "categorical_features = [22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio_of_training):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    p = np.random.permutation(np.arange(y.shape[0]))\n",
    "    n = int(y.shape[0] * ratio_of_training)\n",
    "    return  x[p][:n], x[p][n:], y[p][:n], y[p][n:]\n",
    "\n",
    "def prediction(tx, w):\n",
    "    y = tx @ w\n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 0\n",
    "    return y\n",
    "\n",
    "def accuracy(y, y_pred):\n",
    "    return np.mean(y == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_y(y):\n",
    "    tmp = y.copy()\n",
    "    tmp[tmp==-1]=0\n",
    "    return tmp\n",
    "\n",
    "def transform_y_back(y):\n",
    "    tmp = y.copy()\n",
    "    tmp[tmp==0]=-1  \n",
    "    return tmp\n",
    "\n",
    "def prediction_and_accuracy(tr_tx, tr_y, te_tx, te_y, w):\n",
    "    return accuracy(tr_y, prediction(tr_tx, w)), accuracy(te_y, prediction(te_tx, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fill missing values with their means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEKCAYAAAA8QgPpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106090128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "from IPython.display import display\n",
    "\n",
    "def fill_na(method=np.mean):\n",
    "    filled = tX.copy()\n",
    "    for col in columns_with_missing_values:\n",
    "        tmp = filled[:, col]\n",
    "        tmp[tmp == -999] = method(tmp[tmp != -999])\n",
    "        filled[:, col] = tmp\n",
    "    return filled\n",
    "\n",
    "def plot_hist(tx, i, transformation=None):\n",
    "    plt.figure()\n",
    "    if transformation is None:\n",
    "        plt.hist(tx[:, i], bins=100)\n",
    "    else:\n",
    "        plt.hist(transformation(tx[:, i]), bins=100)\n",
    "    plt.title(\"feature %i\" % i)\n",
    "    plt.show()\n",
    "    \n",
    "# before processing \n",
    "interactive(lambda x:plot_hist(tX, x), x=IntSlider(min=0, max=29))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expand features to reduce bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   0,   1,   0,   1],\n",
       "       [  2,   3,   4,   9,   8,  27],\n",
       "       [  4,   5,  16,  25,  64, 125],\n",
       "       [  6,   7,  36,  49, 216, 343],\n",
       "       [  8,   9,  64,  81, 512, 729]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_polynomial_without_mixed_term(tx, degree=2):\n",
    "    n = tx.shape[0]\n",
    "    tmp = tx\n",
    "    for i in range(2, degree+1):\n",
    "        tmp = np.c_[tmp, tx**i]\n",
    "    # The function standardize will add a column of 1s in the first column\n",
    "    return tmp\n",
    "\n",
    "build_polynomial_without_mixed_term(np.arange(10).reshape(5,2), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 1\n",
    "\n",
    "specifications\n",
    "    - polynomial of degree 2\n",
    "    - didin't apply log to some features\n",
    "    - validation (not cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill -999 with mean/median/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 13, 16, 19, 21, 22, 23, 26, 29]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_tX = fill_na()\n",
    "\n",
    "columns_non_negative = []\n",
    "for i in range(n_total_features):\n",
    "    if len(filled_tX[filled_tX[:, i] < 0, i]) == 0:\n",
    "        columns_non_negative.append(i)\n",
    "\n",
    "columns_non_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the data used for interactive data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105f6fa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(lambda x:plot_hist(filled_tX, x), x=IntSlider(value=1, min=0, max=n_total_features-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some of the data is not allowed to perform log\n",
    "def plot_function(idx):\n",
    "    if idx in columns_non_negative:\n",
    "        plot_hist(filled_tX, idx, lambda y: np.log(y+1e-6))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "interactive(plot_function, idx=IntSlider(value=1, min=0, max=n_total_features-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardize the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 61)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = build_polynomial_without_mixed_term(filled_tX, degree = 2)\n",
    "## We can take logs of each column Here *******************************\n",
    "tX1, mean_x1, std_x1 = standardize(tmp)\n",
    "y1 = transform_y(y)\n",
    "tX1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sepearte training sets and cross validation sets and Predict w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 61)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ratio = 0.9\n",
    "train_tX1, cv_tX1, train_y1, cv_y1 = split_data(tX1, y1, training_ratio)\n",
    "cv_tX1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_info = np.array(info)\n",
    "sizes = plot_info[:, 2]\n",
    "tr_error = plot_info[:, 0]\n",
    "te_error = plot_info[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEACAYAAACd2SCPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSimlGuX/AXK3XDI07Vs5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124c7a320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sizes, tr_error, 'r*-', sizes, te_error, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For how large the size, we can train it very accurately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma=0.1\n",
    "lambda=0.01\n",
    "\n",
    "|training size|iteration| acc train| acc test|\n",
    "|:--:|:---:|:---:|\n",
    "|100|1000| 0.98|0.70|\n",
    "|150|1000|0.88|0.7|\n",
    "|150|5000|0.93|0.71|\n",
    "|150|10000|0.96|0.72464|\n",
    "|150|20000|0.947|0.707|\n",
    "|150|20000|0.953333333333| 0.70664|\n",
    "|200|10000|0.885| 0.70876|\n",
    "|10000|1000|0.6934| 0.69128|\n",
    "\n",
    "we can see that with the grow of training size, the same classifier performs bad on traing set very quickly. For the same training sets, the grows of iterations can improve training performance, but can hardly influence test error.\n",
    "\n",
    "Our model suffers from bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losgistic Regression(0/2000): loss=2402.6957352974205\n",
      "Losgistic Regression(100/2000): loss=-8936.355222308823\n",
      "Losgistic Regression(200/2000): loss=-12594.63835008598\n",
      "Losgistic Regression(300/2000): loss=-15025.068421770844\n",
      "Losgistic Regression(400/2000): loss=-16851.15727650931\n",
      "Losgistic Regression(500/2000): loss=-18322.24101198037\n",
      "Losgistic Regression(600/2000): loss=-19558.5049300319\n",
      "Losgistic Regression(700/2000): loss=-20626.385404283\n",
      "Losgistic Regression(800/2000): loss=-21566.669930990374\n",
      "Losgistic Regression(900/2000): loss=-22406.45130901868\n",
      "Losgistic Regression(1000/2000): loss=-23164.809899810523\n",
      "Losgistic Regression(1100/2000): loss=-23855.783145353264\n",
      "Losgistic Regression(1200/2000): loss=-24490.046690219195\n",
      "Losgistic Regression(1300/2000): loss=-25075.931566815303\n",
      "Losgistic Regression(1400/2000): loss=-25620.074212802167\n",
      "Losgistic Regression(1500/2000): loss=-26127.85080153295\n",
      "Losgistic Regression(1600/2000): loss=-26603.67822884715\n",
      "Losgistic Regression(1700/2000): loss=-27051.229049840775\n",
      "Losgistic Regression(1800/2000): loss=-27473.588850339405\n",
      "Losgistic Regression(1900/2000): loss=-27873.37392097684\n",
      "0.86 0.72992\n"
     ]
    }
   ],
   "source": [
    "idxes = np.arange(200)\n",
    "w, losses = reg_logistic_regression_GD(train_y1[idxes], train_tX1[idxes], gamma=0.001, \n",
    "                       max_iters = 2000, lambda_=0, regularizor=regularizor_lasso)\n",
    "\n",
    "tr_acc, te_acc = prediction_and_accuracy(train_tX1[idxes], train_y1[idxes], cv_tX1, cv_y1, w)\n",
    "print(tr_acc, te_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the (original) feature 2, 4, 15, 18 has small feature in in it self, but their square can be large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error 0.6986177777777778\n",
      "training error 0.69612\n"
     ]
    }
   ],
   "source": [
    "print (\"training error {e}\".format(e=))\n",
    "print (\"training error {e}\".format(e=))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classfier 2: Higher Order Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 13, 16, 19, 21, 22, 23, 26, 29]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_tX = fill_na()\n",
    "\n",
    "columns_non_negative = []\n",
    "for i in range(n_total_features):\n",
    "    if len(filled_tX[filled_tX[:, i] < 0, i]) == 0:\n",
    "        columns_non_negative.append(i)\n",
    "\n",
    "columns_non_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardize the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 91)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = build_polynomial_without_mixed_term(filled_tX, degree = 3)\n",
    "## We can take logs of each column Here *******************************\n",
    "tX2, mean_x2, std_x2 = standardize(tmp)\n",
    "y2 = transform_y(y)\n",
    "tX2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sepearte training sets and cross validation sets and Predict w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 91)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ratio = 0.9\n",
    "train_tX2, cv_tX2, train_y2, cv_y2 = split_data(tX2, y2, training_ratio)\n",
    "cv_tX2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31858812606e-05\n",
      "Losgistic Regression(0/100000): loss=-1576381.4131746194\n",
      "Losgistic Regression(1000/100000): loss=-2609588.730715125\n",
      "Losgistic Regression(2000/100000): loss=-3167813.2138219867\n",
      "Losgistic Regression(3000/100000): loss=-3472116.763273852\n",
      "Losgistic Regression(4000/100000): loss=-3685713.505443715\n",
      "Losgistic Regression(5000/100000): loss=-3849144.4587358832\n",
      "Losgistic Regression(6000/100000): loss=-3981252.780542511\n",
      "Losgistic Regression(7000/100000): loss=-4091986.6941092336\n",
      "Losgistic Regression(8000/100000): loss=-4187103.3739277883\n",
      "Losgistic Regression(9000/100000): loss=-4270247.950210498\n",
      "Losgistic Regression(10000/100000): loss=-4343888.490349865\n",
      "Losgistic Regression(11000/100000): loss=-4409771.966527175\n",
      "Losgistic Regression(12000/100000): loss=-4469173.647771348\n",
      "Losgistic Regression(13000/100000): loss=-4523053.768381426\n",
      "Losgistic Regression(14000/100000): loss=-4572165.075756724\n",
      "Losgistic Regression(15000/100000): loss=-4617120.198719306\n",
      "Losgistic Regression(16000/100000): loss=-4658431.460440949\n",
      "Losgistic Regression(17000/100000): loss=-4696533.776438372\n",
      "Losgistic Regression(18000/100000): loss=-4731798.785862885\n",
      "Losgistic Regression(19000/100000): loss=-4764546.182064939\n",
      "Losgistic Regression(20000/100000): loss=-4795051.625150841\n",
      "Losgistic Regression(21000/100000): loss=-4823553.743449943\n",
      "Losgistic Regression(22000/100000): loss=-4850259.862277383\n",
      "Losgistic Regression(23000/100000): loss=-4875350.531390548\n",
      "Losgistic Regression(24000/100000): loss=-4898983.454344895\n",
      "Losgistic Regression(25000/100000): loss=-4921297.340273586\n",
      "Losgistic Regression(26000/100000): loss=-4942413.462051473\n",
      "Losgistic Regression(27000/100000): loss=-4962438.986907133\n",
      "Losgistic Regression(28000/100000): loss=-4981468.558170063\n",
      "Losgistic Regression(29000/100000): loss=-4999585.841008508\n",
      "Losgistic Regression(30000/100000): loss=-5016864.965058875\n",
      "Losgistic Regression(31000/100000): loss=-5033371.745346901\n",
      "Losgistic Regression(32000/100000): loss=-5049164.741337445\n",
      "Losgistic Regression(33000/100000): loss=-5064296.186086943\n",
      "Losgistic Regression(34000/100000): loss=-5078812.804623643\n",
      "Losgistic Regression(35000/100000): loss=-5092756.393514927\n",
      "Losgistic Regression(36000/100000): loss=-5106165.058016837\n",
      "Losgistic Regression(37000/100000): loss=-5119072.781526758\n",
      "Losgistic Regression(38000/100000): loss=-5131511.020404617\n",
      "Losgistic Regression(39000/100000): loss=-5143507.664347334\n",
      "Losgistic Regression(40000/100000): loss=-5155088.63508416\n",
      "Losgistic Regression(41000/100000): loss=-5166277.743503345\n",
      "Losgistic Regression(42000/100000): loss=-5177096.9263597075\n",
      "Losgistic Regression(43000/100000): loss=-5187566.4487711685\n",
      "Losgistic Regression(44000/100000): loss=-5197705.050099795\n",
      "Losgistic Regression(45000/100000): loss=-5207530.119119958\n",
      "Losgistic Regression(46000/100000): loss=-5217057.79366191\n",
      "Losgistic Regression(47000/100000): loss=-5226303.074583019\n",
      "Losgistic Regression(48000/100000): loss=-5235279.921821131\n",
      "Losgistic Regression(49000/100000): loss=-5244001.340726925\n",
      "Losgistic Regression(50000/100000): loss=-5252479.46022717\n",
      "Losgistic Regression(51000/100000): loss=-5260725.603928999\n",
      "Losgistic Regression(52000/100000): loss=-5268750.354984655\n",
      "Losgistic Regression(53000/100000): loss=-5276563.615347583\n",
      "Losgistic Regression(54000/100000): loss=-5284174.659932345\n",
      "Losgistic Regression(55000/100000): loss=-5291592.18611666\n",
      "Losgistic Regression(56000/100000): loss=-5298824.358974835\n",
      "Losgistic Regression(57000/100000): loss=-5305878.852597846\n",
      "Losgistic Regression(58000/100000): loss=-5312762.887828574\n",
      "Losgistic Regression(59000/100000): loss=-5319483.252422188\n",
      "Losgistic Regression(60000/100000): loss=-5326046.3873747615\n",
      "Losgistic Regression(61000/100000): loss=-5332458.353504039\n",
      "Losgistic Regression(62000/100000): loss=-5338724.852569162\n",
      "Losgistic Regression(63000/100000): loss=-5344851.300808033\n",
      "Losgistic Regression(64000/100000): loss=-5350842.828958583\n",
      "Losgistic Regression(65000/100000): loss=-5356704.300721952\n",
      "Losgistic Regression(66000/100000): loss=-5362440.331261646\n",
      "Losgistic Regression(67000/100000): loss=-5368055.304237758\n",
      "Losgistic Regression(68000/100000): loss=-5373553.387373273\n",
      "Losgistic Regression(69000/100000): loss=-5378938.546697936\n",
      "Losgistic Regression(70000/100000): loss=-5384214.559610502\n",
      "Losgistic Regression(71000/100000): loss=-5389385.026880057\n",
      "Losgistic Regression(72000/100000): loss=-5394453.383690101\n",
      "Losgistic Regression(73000/100000): loss=-5399422.909817011\n",
      "Losgistic Regression(74000/100000): loss=-5404296.739022105\n",
      "Losgistic Regression(75000/100000): loss=-5409077.867729876\n",
      "Losgistic Regression(76000/100000): loss=-5413769.163055664\n",
      "Losgistic Regression(77000/100000): loss=-5418373.370240863\n",
      "Losgistic Regression(78000/100000): loss=-5422893.119547225\n",
      "Losgistic Regression(79000/100000): loss=-5427330.9326570975\n",
      "Losgistic Regression(80000/100000): loss=-5431689.228621795\n",
      "Losgistic Regression(81000/100000): loss=-5435970.329396363\n",
      "Losgistic Regression(82000/100000): loss=-5440176.464994871\n",
      "Losgistic Regression(83000/100000): loss=-5444309.778297924\n",
      "Losgistic Regression(84000/100000): loss=-5448372.329540389\n",
      "Losgistic Regression(85000/100000): loss=-5452366.100504982\n",
      "Losgistic Regression(86000/100000): loss=-5456293.185446158\n",
      "Losgistic Regression(87000/100000): loss=-5460155.1175794825\n",
      "Losgistic Regression(88000/100000): loss=-5463953.779596244\n",
      "Losgistic Regression(89000/100000): loss=-5467690.875100382\n",
      "Losgistic Regression(90000/100000): loss=-5471368.045793549\n",
      "Losgistic Regression(91000/100000): loss=-5474986.876479005\n",
      "Losgistic Regression(92000/100000): loss=-5478548.896940535\n",
      "Losgistic Regression(93000/100000): loss=-5482055.584147429\n",
      "Losgistic Regression(94000/100000): loss=-5485508.364485841\n",
      "Losgistic Regression(95000/100000): loss=-5488908.615921628\n",
      "Losgistic Regression(96000/100000): loss=-5492257.670073381\n",
      "Losgistic Regression(97000/100000): loss=-5495556.814190101\n",
      "Losgistic Regression(98000/100000): loss=-5498807.293032587\n",
      "Losgistic Regression(99000/100000): loss=-5502010.310660532\n",
      "0.8172 0.80656\n"
     ]
    }
   ],
   "source": [
    "idxes = np.arange(5000)\n",
    "L=np.linalg.eigvals(train_tX2[idxes].T @ train_tX2[idxes]).max()\n",
    "print(1/L)\n",
    "w, losses = reg_logistic_regression_GD(train_y2[idxes], train_tX2[idxes], gamma=1/L, \n",
    "                       max_iters = 100000, lambda_=0.0001, regularizor=regularizor_lasso)\n",
    "\n",
    "tr_acc, te_acc = prediction_and_accuracy(train_tX2[idxes], train_y2[idxes], cv_tX2, cv_y2, w)\n",
    "print(tr_acc, te_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.6932772662e-06\n",
      "Losgistic Regression(0/100000): loss=434457.21842224855\n",
      "Losgistic Regression(1000/100000): loss=-10234622.776920963\n",
      "Losgistic Regression(2000/100000): loss=-12230873.927219868\n",
      "Losgistic Regression(3000/100000): loss=-13370184.385959959\n",
      "Losgistic Regression(4000/100000): loss=-14177368.686676051\n",
      "Losgistic Regression(5000/100000): loss=-14804224.395295477\n",
      "Losgistic Regression(6000/100000): loss=-15313039.706620015\n",
      "Losgistic Regression(7000/100000): loss=-15737437.263241317\n",
      "Losgistic Regression(8000/100000): loss=-16098504.39866479\n",
      "Losgistic Regression(9000/100000): loss=-16410311.024095053\n",
      "Losgistic Regression(10000/100000): loss=-16682700.350381702\n",
      "Losgistic Regression(11000/100000): loss=-16922849.827691004\n",
      "Losgistic Regression(12000/100000): loss=-17136175.98913687\n",
      "Losgistic Regression(13000/100000): loss=-17326879.368117437\n",
      "Losgistic Regression(14000/100000): loss=-17498293.407778494\n",
      "Losgistic Regression(15000/100000): loss=-17653107.48084559\n",
      "Losgistic Regression(16000/100000): loss=-17793529.65548029\n",
      "Losgistic Regression(17000/100000): loss=-17921393.395987857\n",
      "Losgistic Regression(18000/100000): loss=-18038237.25761377\n",
      "Losgistic Regression(19000/100000): loss=-18145364.019332215\n",
      "Losgistic Regression(20000/100000): loss=-18243884.099737927\n",
      "Losgistic Regression(21000/100000): loss=-18334751.18453073\n",
      "Losgistic Regression(22000/100000): loss=-18418786.030906536\n",
      "Losgistic Regression(23000/100000): loss=-18496700.57322757\n",
      "Losgistic Regression(24000/100000): loss=-18569113.75459297\n",
      "Losgistic Regression(25000/100000): loss=-18636565.985747747\n",
      "Losgistic Regression(26000/100000): loss=-18699530.91251867\n",
      "Losgistic Regression(27000/100000): loss=-18758425.16131391\n",
      "Losgistic Regression(28000/100000): loss=-18813617.131521203\n",
      "Losgistic Regression(29000/100000): loss=-18865433.07428224\n",
      "Losgistic Regression(30000/100000): loss=-18914163.557746664\n",
      "Losgistic Regression(31000/100000): loss=-18960068.0583519\n",
      "Losgistic Regression(32000/100000): loss=-19003378.944174524\n",
      "Losgistic Regression(33000/100000): loss=-19044304.78913666\n",
      "Losgistic Regression(34000/100000): loss=-19083033.163536843\n",
      "Losgistic Regression(35000/100000): loss=-19119733.020641763\n",
      "Losgistic Regression(36000/100000): loss=-19154556.770490967\n",
      "Losgistic Regression(37000/100000): loss=-19187642.10459073\n",
      "Losgistic Regression(38000/100000): loss=-19219113.613513943\n",
      "Losgistic Regression(39000/100000): loss=-19249083.985745035\n",
      "Losgistic Regression(40000/100000): loss=-19277656.17267111\n",
      "Losgistic Regression(41000/100000): loss=-19304923.26221315\n",
      "Losgistic Regression(42000/100000): loss=-19330970.35926909\n",
      "Losgistic Regression(43000/100000): loss=-19355875.180184305\n",
      "Losgistic Regression(44000/100000): loss=-19379708.859251298\n",
      "Losgistic Regression(45000/100000): loss=-19402536.647963177\n",
      "Losgistic Regression(46000/100000): loss=-19424418.52547581\n",
      "Losgistic Regression(47000/100000): loss=-19445409.734691165\n",
      "Losgistic Regression(48000/100000): loss=-19465561.254464686\n",
      "Losgistic Regression(49000/100000): loss=-19484920.21633419\n",
      "Losgistic Regression(50000/100000): loss=-19503530.27297856\n",
      "Losgistic Regression(51000/100000): loss=-19521431.924608763\n",
      "Losgistic Regression(52000/100000): loss=-19538662.808669314\n",
      "Losgistic Regression(53000/100000): loss=-19555257.95751001\n",
      "Losgistic Regression(54000/100000): loss=-19571250.028062366\n",
      "Losgistic Regression(55000/100000): loss=-19586669.621781625\n",
      "Losgistic Regression(56000/100000): loss=-19601544.96572731\n",
      "Losgistic Regression(57000/100000): loss=-19615902.92292718\n",
      "Losgistic Regression(58000/100000): loss=-19629768.48523869\n",
      "Losgistic Regression(59000/100000): loss=-19643165.110032324\n",
      "Losgistic Regression(60000/100000): loss=-19656115.52071395\n",
      "Losgistic Regression(61000/100000): loss=-19668639.440809503\n",
      "Losgistic Regression(62000/100000): loss=-19680756.558475815\n",
      "Losgistic Regression(63000/100000): loss=-19692485.377999134\n",
      "Losgistic Regression(64000/100000): loss=-19703843.2780626\n",
      "Losgistic Regression(65000/100000): loss=-19714846.658731826\n",
      "Losgistic Regression(66000/100000): loss=-19725511.017401554\n",
      "Losgistic Regression(67000/100000): loss=-19735851.0127058\n",
      "Losgistic Regression(68000/100000): loss=-19745880.52210366\n",
      "Losgistic Regression(69000/100000): loss=-19755612.69436495\n",
      "Losgistic Regression(70000/100000): loss=-19765059.997607972\n",
      "Losgistic Regression(71000/100000): loss=-19774234.26339828\n",
      "Losgistic Regression(72000/100000): loss=-19783146.727319214\n",
      "Losgistic Regression(73000/100000): loss=-19791808.066357877\n",
      "Losgistic Regression(74000/100000): loss=-19800228.433412656\n",
      "Losgistic Regression(75000/100000): loss=-19808417.489186414\n",
      "Losgistic Regression(76000/100000): loss=-19816384.43170213\n",
      "Losgistic Regression(77000/100000): loss=-19824138.023650773\n",
      "Losgistic Regression(78000/100000): loss=-19831686.617763985\n",
      "Losgistic Regression(79000/100000): loss=-19839038.180371005\n",
      "Losgistic Regression(80000/100000): loss=-19846200.40784303\n",
      "Losgistic Regression(81000/100000): loss=-19853180.31290167\n",
      "Losgistic Regression(82000/100000): loss=-19859985.01820347\n",
      "Losgistic Regression(83000/100000): loss=-19866621.119001914\n",
      "Losgistic Regression(84000/100000): loss=-19873094.94309165\n",
      "Losgistic Regression(85000/100000): loss=-19879412.547330413\n",
      "Losgistic Regression(86000/100000): loss=-19885579.728835315\n",
      "Losgistic Regression(87000/100000): loss=-19891602.03770426\n",
      "Losgistic Regression(88000/100000): loss=-19897484.78940485\n",
      "Losgistic Regression(89000/100000): loss=-19903233.07653867\n",
      "Losgistic Regression(90000/100000): loss=-19908851.77993583\n",
      "Losgistic Regression(91000/100000): loss=-19914345.57909794\n",
      "Losgistic Regression(92000/100000): loss=-19919718.96202289\n",
      "Losgistic Regression(93000/100000): loss=-19924976.2344513\n",
      "Losgistic Regression(94000/100000): loss=-19930121.528572276\n",
      "Losgistic Regression(95000/100000): loss=-19935158.811225545\n",
      "Losgistic Regression(96000/100000): loss=-19940091.891634226\n",
      "Losgistic Regression(97000/100000): loss=-19944924.428700306\n",
      "Losgistic Regression(98000/100000): loss=-19949659.93789192\n",
      "Losgistic Regression(99000/100000): loss=-19954301.79774978\n",
      "0.8108 0.8062\n"
     ]
    }
   ],
   "source": [
    "idxes = np.arange(10000)\n",
    "L=np.linalg.eigvals(train_tX2[idxes].T @ train_tX2[idxes]).max()\n",
    "print(1/L)\n",
    "w, losses = reg_logistic_regression_GD(train_y2[idxes], train_tX2[idxes], gamma=1/L, \n",
    "                       max_iters = 100000, lambda_=0.0001, regularizor=regularizor_lasso)\n",
    "\n",
    "tr_acc, te_acc = prediction_and_accuracy(train_tX2[idxes], train_y2[idxes], cv_tX2, cv_y2, w)\n",
    "print(tr_acc, te_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  7, 10, 13, 16,  0,  2,  8,  9, 13, 19,  0,  1,  3,  9, 13, 19,\n",
       "        0])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(91)[abs(w)>1]%30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_features(tx, cols):\n",
    "    return tx[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = build_polynomial_without_mixed_term(filled_tX, degree = 4)\n",
    "## We can take logs of each column Here *******************************\n",
    "tX3, mean_x3, std_x3 = standardize(tmp)\n",
    "y3 = transform_y(y)\n",
    "tX3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxes = np.arange(10000)\n",
    "L=np.linalg.eigvals(train_tX3[idxes].T @ train_tX3[idxes]).max()\n",
    "print(1/L)\n",
    "w, losses = reg_logistic_regression_GD(train_y3[idxes], train_tX3[idxes], gamma=1/L, \n",
    "                       max_iters = 100000, lambda_=0.0001, regularizor=regularizor_lasso)\n",
    "\n",
    "tr_acc, te_acc = prediction_and_accuracy(train_tX3[idxes], train_y3[idxes], cv_tX3, cv_y3, w)\n",
    "print(tr_acc, te_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 30)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 13, 16, 19, 21, 22, 23, 26, 29]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fill_na_test(method=np.mean):\n",
    "    filled = tX_test.copy()\n",
    "    for col in columns_with_missing_values:\n",
    "        tmp = filled[:, col]\n",
    "        tmp[tmp == -999] = method(tmp[tmp != -999])\n",
    "        filled[:, col] = tmp\n",
    "    return filled\n",
    "\n",
    "\n",
    "filled_test_tX = fill_na_test()\n",
    "\n",
    "columns_non_negative = []\n",
    "for i in range(n_total_features):\n",
    "    if len(filled_test_tX[filled_test_tX[:, i] < 0, i]) == 0:\n",
    "        columns_non_negative.append(i)\n",
    "\n",
    "columns_non_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 91)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = build_polynomial_without_mixed_term(filled_test_tX, degree = 3)\n",
    "## We can take logs of each column Here *******************************\n",
    "test_tX, _, _ = standardize(tmp, mean_x2, std_x2)\n",
    "test_tX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y0=transform_y_back(prediction(test_tX, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177703,)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0[y0==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../results/result3.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = transform_y_back(y0)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "023cb81475a945fe97d29be3cb3600e9": {
     "views": []
    },
    "0656d01812174c589117e89a7f476eeb": {
     "views": []
    },
    "06e08db57e4c4440a3ad1b3951854893": {
     "views": []
    },
    "09d8152e0e4842f281b6992d966f84ff": {
     "views": []
    },
    "0b17fa30a11f499bbbb6b8402e16c6c0": {
     "views": []
    },
    "0e1159612a454425bbac65a45bf46ae4": {
     "views": []
    },
    "0e2681dfe3854507b8e382172c8d24a9": {
     "views": []
    },
    "0e3a8a0386ac4eeabbe0d75c720fe8ca": {
     "views": []
    },
    "12028e93822d44fb98bff43ebb5ae85f": {
     "views": []
    },
    "12c1d615bd694bcea1fd9ab1124e2733": {
     "views": []
    },
    "17693f1c9ae243fba5f88f6bd0563d5c": {
     "views": []
    },
    "19e769fc042640babb5295d1974c62b8": {
     "views": []
    },
    "19ee98066002482e9fc35c5c1daf61ba": {
     "views": []
    },
    "1a632485f2d8478193df72588650d618": {
     "views": []
    },
    "1a86c3fa0e2d4cd0b5251249d12134bc": {
     "views": []
    },
    "1ee72dc401884de7b2faf7aa90592e2e": {
     "views": []
    },
    "1f1d9fd36c85413abd59a0c5d2f6afac": {
     "views": []
    },
    "218b8bbbb96c44759803d1d7bb93518b": {
     "views": []
    },
    "22ac1bf8dc1a42ec9f6bf037c2b351e0": {
     "views": []
    },
    "2691c30802414c95b1e293e0281cb59c": {
     "views": []
    },
    "2802b13066f649798d7bf253e4bb2b91": {
     "views": []
    },
    "2f8de774e24d4bfbbe7fc7a6c589165b": {
     "views": []
    },
    "33a6f920af1a414eb26969a29ca0e9f5": {
     "views": []
    },
    "33d5f66f8db64bb29aee64e9e6f4b00a": {
     "views": []
    },
    "358ab636ff8949958e22afe4df4c92f5": {
     "views": []
    },
    "360a79441c40473eac4ed7aa38bc332e": {
     "views": []
    },
    "3732e557ec5f4420ae4be9ba1b0c6950": {
     "views": []
    },
    "3891a8618a4e46e0a33e3c1fc96e927f": {
     "views": []
    },
    "3b1570fddde04f0caf52f4ff45d29edb": {
     "views": []
    },
    "3d44ad00ad504e909c2c5165179b38f3": {
     "views": []
    },
    "3ff3abd2ef184017be0348ce847f1a3b": {
     "views": []
    },
    "4104a7b34dea4cac9f83200068a87e4e": {
     "views": []
    },
    "411967c7a0484176b05d585607f58205": {
     "views": []
    },
    "42a2771cc4de461b8e1f7930eb1a5b05": {
     "views": []
    },
    "43533ec6a6424e228d82dedae9d2e033": {
     "views": []
    },
    "44341b3861874225ac2c4a39d9e9b20a": {
     "views": []
    },
    "4514ac6a980d4c1cb0b2865b036f78b4": {
     "views": [
      {
       "cell_index": 132
      }
     ]
    },
    "462a940358654d2b84aa86fb2ddb7fa5": {
     "views": []
    },
    "467d39db9951416ca21632ab9321781c": {
     "views": []
    },
    "48db65e31eb143489065ea6f27cdafee": {
     "views": []
    },
    "4a47e66ec8f145b2a4ce40452beb05eb": {
     "views": []
    },
    "4e8c9deaad524bda8b1da06a0ec346ca": {
     "views": []
    },
    "514aac3eeee24c6d950fdbc506e2c983": {
     "views": []
    },
    "51600ba1f25f46f28712de210eecac48": {
     "views": []
    },
    "53b9a6a0056f4d3eb3d049a6b79902e6": {
     "views": []
    },
    "54f2df5f3b374a7b92906e2c6f9ec3b6": {
     "views": []
    },
    "55a0f08bc43a45199474b57bfab46e44": {
     "views": []
    },
    "5608d42ea9e94999ab42b8ad0c206f85": {
     "views": []
    },
    "58b9d8f8c94d4706bfa0fb67ecbbd1c8": {
     "views": []
    },
    "59566267562941e28c581d183adfb31b": {
     "views": []
    },
    "59b6af240339412ca33740de32807e72": {
     "views": []
    },
    "5c9a253daa9641bdb41bb1e907995314": {
     "views": []
    },
    "5da1672732bf4560a2f195fbfa18fd2f": {
     "views": []
    },
    "5f61c6f48bc6407f808b26dfd3ff650e": {
     "views": []
    },
    "60025b85d7d7483cbd0389d15fa40b24": {
     "views": []
    },
    "6290e48913ff4b9785efd7c0fc29e29a": {
     "views": []
    },
    "64aa7fe3a5964b7289a6e95b667b7697": {
     "views": []
    },
    "68319ce5b3a74f10b5004a4a7e6e9bde": {
     "views": []
    },
    "69b3066124164f6e9fee59423542e6ce": {
     "views": []
    },
    "6f2439baf7df4a6ba620e3c431601ec5": {
     "views": []
    },
    "712bf0da5abb466daed7cb112ac4be9f": {
     "views": []
    },
    "737b5fb46e5647d58c0167b33056f32d": {
     "views": []
    },
    "74e7c1ac51d44ba99eb3190482e44c9f": {
     "views": []
    },
    "74f46c0299024dbd9fa900a91a41e71c": {
     "views": []
    },
    "7646e6b27e164eb4a922f3369c0d1359": {
     "views": []
    },
    "76716f91d3974e5188e3ce2031b8edc6": {
     "views": []
    },
    "7856af6c59bf4b02ad553e5de1667e6e": {
     "views": []
    },
    "84cc99bad75e48c79fd29af3b3b6cf23": {
     "views": []
    },
    "8554ffcd85804c4480cb9568679288e6": {
     "views": []
    },
    "86d8b3ca74394075a5040754a7d0f112": {
     "views": []
    },
    "8712c2d770b044e580b70be8ff47a70c": {
     "views": []
    },
    "89e5d5a410f148b3b9f038d07b985826": {
     "views": []
    },
    "8bc31e9d2e244f859b9944277b10685e": {
     "views": []
    },
    "8c8280c2e5e843ea912ce840c1f9a815": {
     "views": []
    },
    "8de53ca2548b46ffa4709418cdc5e47a": {
     "views": []
    },
    "8f571f7019b648d6982443a00678ca09": {
     "views": []
    },
    "8fd8e55f342e4cd2854b16ae86e8431b": {
     "views": []
    },
    "905c684e215f46b9851f87a98a19cbe8": {
     "views": []
    },
    "910792a394e442a2b3537417187c38f0": {
     "views": [
      {
       "cell_index": 137
      }
     ]
    },
    "92c8926847d9495698e180d643661298": {
     "views": []
    },
    "957d7a710a95407ba7de2bc66a90cb87": {
     "views": []
    },
    "95b6733c17ac4871b980ba45f329b81e": {
     "views": []
    },
    "971324d43edb41bc906914d34cac4e84": {
     "views": []
    },
    "97aa3c9800f04dff94ded3f655bfda84": {
     "views": []
    },
    "9873d25dd712418e87df9d8e7d1140d3": {
     "views": [
      {
       "cell_index": 137
      }
     ]
    },
    "9cdc11d2dbb545308ed63a064fc63ece": {
     "views": []
    },
    "9f070cfb9678487d907255f42842b0fb": {
     "views": []
    },
    "9fedd7eee0504abbad19cbda3aebb022": {
     "views": []
    },
    "9ffc35d8432c40ee9895c565f3c4abda": {
     "views": []
    },
    "a0a41254ad204744aa98206b576555d0": {
     "views": []
    },
    "a72d857b82d54d389cc8a371a4b03d39": {
     "views": []
    },
    "a74ee4818b264fbb95d165877824da55": {
     "views": []
    },
    "a9f0e192ef384cabb84c130bb60cfaea": {
     "views": []
    },
    "aa47af235b6e4335a9843f236ab8fef9": {
     "views": []
    },
    "aafafbbeae1c40cebeb269ac6833d061": {
     "views": []
    },
    "af20bec9e7a54c8ea66dc4787a3a09ea": {
     "views": []
    },
    "b1b641006f214f70a713be0f41831858": {
     "views": []
    },
    "b4c1f164f05b4f3bb3a437b454a9e499": {
     "views": []
    },
    "ba3ea59619e4415b9aa586a7af6b945a": {
     "views": []
    },
    "bbd68922ec024005a35d8f6c24577f3c": {
     "views": []
    },
    "bc3a26e14c1e4962a46cf7287e8991b6": {
     "views": []
    },
    "bf54fb7095864dcba467fe64fb76a32d": {
     "views": []
    },
    "bfa043dfddd741abb68307bd0bff96b2": {
     "views": []
    },
    "c0f3489352ed4aa3b0b6ab1abb9777d8": {
     "views": []
    },
    "c107053cbde24768a5c39237e591246f": {
     "views": []
    },
    "c2853ffd303b4614aeeac08b8f09141a": {
     "views": []
    },
    "c7dc57c0cd694805bac3f843578ae253": {
     "views": []
    },
    "ca45a1359d0a47bf93208f7941df740a": {
     "views": []
    },
    "cc59f3ba01b04abfa8cd8b84857ed625": {
     "views": []
    },
    "cc6eb0825e3b4e6991f36100c530879f": {
     "views": []
    },
    "ce5f660489ae4eb68bec161d9d3afce6": {
     "views": []
    },
    "cf32fbdee557427e8a9d06c5e36c7d24": {
     "views": []
    },
    "d3c5139772f14218afa6d3cf87edefb9": {
     "views": []
    },
    "d5d8edac095d4c858774ee96236435c0": {
     "views": []
    },
    "d76b311a962d49bd9af777ff5f3f6132": {
     "views": []
    },
    "da3ca8bd2ea84ef39e5e1280c6bebc25": {
     "views": []
    },
    "de3928afe68841acb45bd27c88dcb8f5": {
     "views": []
    },
    "df04152de8aa4696b0ffd12180b89e9c": {
     "views": []
    },
    "df0bf6fbe6514083a3c8dc0d19a23b2d": {
     "views": []
    },
    "e0ea1699749a41e687b5683624033244": {
     "views": []
    },
    "e2645b8789c242e18c5db1e0997cf20d": {
     "views": []
    },
    "e3e681e437c3484cb7f49bd2f0655669": {
     "views": []
    },
    "e841538f7d8742289247f2aa9626b7da": {
     "views": []
    },
    "e972522844ca40e1b9378bcffb5ce313": {
     "views": []
    },
    "e9a93b10f7e84f6d9247f21115304861": {
     "views": []
    },
    "eb932c58dcb649c784bd9ed1aef50a74": {
     "views": []
    },
    "ebf85c945d094c6c94f279c3522cf276": {
     "views": []
    },
    "edd161163b4f4188964b434d9a316a75": {
     "views": []
    },
    "ee2859b43dbe405db03026763ff27e6b": {
     "views": []
    },
    "ee4ecf624eb24702a501c36235e105d7": {
     "views": []
    },
    "f140365f0cef4c11b5c5390d1a64edc6": {
     "views": []
    },
    "f16dce26e29447fb92414f4a56c3d000": {
     "views": []
    },
    "f4888ce60df2468389ab39f32b9585b4": {
     "views": []
    },
    "f6930490a4964d05abfd130fcad37587": {
     "views": []
    },
    "f6d9425b6be14c40b50c15979e35be99": {
     "views": []
    },
    "fca522c4fd7a47be86a1aab9fa26494c": {
     "views": []
    },
    "fd7dab3919ab4f0f838fe25f216d2d81": {
     "views": []
    },
    "fec936e794b94e74be9eed7a0c172ba7": {
     "views": []
    }
   },
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
